{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":939937,"sourceType":"datasetVersion","datasetId":501529}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.model_selection import KFold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:50:53.883424Z","iopub.execute_input":"2024-12-29T00:50:53.883654Z","iopub.status.idle":"2024-12-29T00:50:58.672164Z","shell.execute_reply.started":"2024-12-29T00:50:53.883631Z","shell.execute_reply":"2024-12-29T00:50:58.671482Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:59:00.875590Z","iopub.execute_input":"2024-12-29T00:59:00.875937Z","iopub.status.idle":"2024-12-29T00:59:00.950651Z","shell.execute_reply.started":"2024-12-29T00:59:00.875910Z","shell.execute_reply":"2024-12-29T00:59:00.949737Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"folders = [\"test\", \"train\", \"valid\"]\ninner_folders = [\"fake\", \"real\"]\n\ntotal_fake = 0\ntotal_real = 0\n\nfor i in range(len(folders)):\n  for j in range(len(inner_folders)):\n    x = os.listdir(f\"/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake/{folders[i]}/{inner_folders[j]}\")\n    print(f\"Length of {inner_folders[j]} images in {folders[i]} : {len(x)}\")\n    if(inner_folders[j] == \"real\"):\n      total_real += len(x)\n    else:\n      total_fake += len(x)\n\nprint(f\"Total Number of Real images in dataset: {total_real}\")\n\nprint(f\"Total Number of Fake images in dataset: {total_fake}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:59:03.566600Z","iopub.execute_input":"2024-12-29T00:59:03.567000Z","iopub.status.idle":"2024-12-29T00:59:04.356650Z","shell.execute_reply.started":"2024-12-29T00:59:03.566956Z","shell.execute_reply":"2024-12-29T00:59:04.355788Z"}},"outputs":[{"name":"stdout","text":"Length of fake images in test : 10000\nLength of real images in test : 10000\nLength of fake images in train : 50000\nLength of real images in train : 50000\nLength of fake images in valid : 10000\nLength of real images in valid : 10000\nTotal Number of Real images in dataset: 70000\nTotal Number of Fake images in dataset: 70000\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data_dir = \"/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:59:06.406184Z","iopub.execute_input":"2024-12-29T00:59:06.406481Z","iopub.status.idle":"2024-12-29T00:59:06.409919Z","shell.execute_reply.started":"2024-12-29T00:59:06.406456Z","shell.execute_reply":"2024-12-29T00:59:06.409068Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Grayscale(num_output_channels=3),\n        transforms.Resize((64, 64)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Grayscale(num_output_channels=3),\n        transforms.Resize((64, 64)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Grayscale(num_output_channels=3),\n        transforms.Resize((64, 64)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:59:07.974425Z","iopub.execute_input":"2024-12-29T00:59:07.974800Z","iopub.status.idle":"2024-12-29T00:59:07.980350Z","shell.execute_reply.started":"2024-12-29T00:59:07.974767Z","shell.execute_reply":"2024-12-29T00:59:07.979447Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data_dirs = {\n    'train': os.path.join(data_dir, 'train'),\n    'val': os.path.join(data_dir, 'valid'),\n    'test': os.path.join(data_dir, 'test')\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:59:12.037165Z","iopub.execute_input":"2024-12-29T00:59:12.037450Z","iopub.status.idle":"2024-12-29T00:59:12.041282Z","shell.execute_reply.started":"2024-12-29T00:59:12.037428Z","shell.execute_reply":"2024-12-29T00:59:12.040474Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\ntrain_dataset = ImageFolder(root=data_dirs['train'], transform=data_transforms['train'])\nval_dataset = ImageFolder(root=data_dirs['val'], transform=data_transforms['val'])\ntest_dataset = ImageFolder(root=data_dirs['test'], transform=data_transforms['test'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:59:18.094445Z","iopub.execute_input":"2024-12-29T00:59:18.094870Z","iopub.status.idle":"2024-12-29T01:00:45.646730Z","shell.execute_reply.started":"2024-12-29T00:59:18.094833Z","shell.execute_reply":"2024-12-29T01:00:45.645766Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Subset, ConcatDataset\n\n# Total number of samples to select\ntrain_size = 60000\nval_size = 12000\ntest_size = 12000\n\n# Create indices for subsets\ntrain_indices = torch.arange(train_size)\nval_indices = torch.arange(val_size)\ntest_indices = torch.arange(test_size)\n\n# Create subsets\ntrain_subset = Subset(train_dataset, train_indices)\nval_subset = Subset(val_dataset, val_indices)\ntest_subset = Subset(test_dataset, test_indices)\n\n# Create DataLoaders for subsets\ntrain_loader = DataLoader(train_subset, batch_size=200, shuffle=True, pin_memory=True, num_workers=2)\nval_loader = DataLoader(val_subset, batch_size=200, shuffle=False, pin_memory=True, num_workers=2)\ntest_loader = DataLoader(test_subset, batch_size=1, shuffle=False, pin_memory=True, num_workers=2)\n\n# Combine train and validation subsets\ncombined_dataset = ConcatDataset([train_subset, val_subset])\ncombined_loader = DataLoader(combined_dataset, batch_size=200, shuffle=True, pin_memory=True, num_workers=2)\n\nprint(f\"Train set: {len(train_subset)}, Val set: {len(val_subset)}, Test set: {len(test_subset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T01:00:49.670077Z","iopub.execute_input":"2024-12-29T01:00:49.670381Z","iopub.status.idle":"2024-12-29T01:00:49.697997Z","shell.execute_reply.started":"2024-12-29T01:00:49.670355Z","shell.execute_reply":"2024-12-29T01:00:49.697289Z"}},"outputs":[{"name":"stdout","text":"Train set: 60000, Val set: 12000, Test set: 12000\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class CustomMobileNet(nn.Module):\n    def __init__(self):\n        super(CustomMobileNet, self).__init__()\n        mobilenet = models.mobilenet_v2(weights='IMAGENET1K_V1')\n        self.features = mobilenet.features\n        self.classifier = nn.Sequential(\n            nn.Linear(mobilenet.last_channel, 4096),  # Adjust for 64x64 images\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 1)  # Adjust num_classes\n        )\n        # Freeze all parameters initially\n        for param in self.features.parameters():\n            param.requires_grad = False\n    \n        #self.freeze_features()\n    \n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.mean([2, 3])  # Global average pooling\n        x = self.classifier(x)\n        return x\n\n    \n\n    def unfreeze_last_layers(self, num_layers):\n        layers = list(self.features.children())[-num_layers:]\n        for layer in layers:\n            for param in layer.parameters():\n                param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T01:08:02.411019Z","iopub.execute_input":"2024-12-29T01:08:02.411350Z","iopub.status.idle":"2024-12-29T01:08:02.417411Z","shell.execute_reply.started":"2024-12-29T01:08:02.411322Z","shell.execute_reply":"2024-12-29T01:08:02.416591Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from torch.utils.data import DataLoader, ConcatDataset, Subset\n\ndef train_model(model, combined_dataset, criterion, optimizer, num_epochs=10, k=3):\n    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n    \n    \n    fold_metrics = {\n        \"train_losses\": [],\n        \"valid_losses\": [],\n        \"train_accuracies\": [],\n        \"valid_accuracies\": [],\n        \"precisions\": [],\n        \"recalls\": [],\n        \"best_accuracy\": []\n    }\n\n    for fold, (train_idx, valid_idx) in enumerate(kfold.split(combined_dataset)):\n        print(f\"\\nFold {fold+1}/{k}\")\n\n        \n        train_subset = Subset(combined_dataset, train_idx)\n        valid_subset = Subset(combined_dataset, valid_idx)\n\n        train_loader = DataLoader(train_subset, batch_size=200, shuffle=True)\n        valid_loader = DataLoader(valid_subset, batch_size=200, shuffle=False)\n\n        \n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"Using device: {device}\")\n    \n        \n        model = model.to(device)\n        criterion = criterion.to(device)\n\n        best_val_accuracy = 0.0\n        fold_precision = 0\n        fold_recall = 0\n\n        for epoch in range(num_epochs):\n            model.train()\n            running_loss = 0.0\n            correct = 0\n            total = 0\n\n            \n            with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\", total=len(train_loader)) as tepoch:\n                for inputs, labels in tepoch:\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    labels = labels.float()  # Ensure labels are float for BCEWithLogitsLoss\n\n                    optimizer.zero_grad()\n\n                    # Forward pass\n                    outputs = model(inputs)\n                    loss = criterion(outputs.squeeze(), labels) \n\n                    # Backward pass and optimization\n                    loss.backward()\n                    optimizer.step()\n\n                    # Track training statistics\n                    running_loss += loss.item()\n                    preds = torch.round(torch.sigmoid(outputs))\n                    correct += (preds.squeeze() == labels).sum().item()\n                    total += labels.size(0)\n\n                    # Update progress bar\n                    tepoch.set_postfix(loss=running_loss / (tepoch.n + 1), accuracy=correct / total * 100)\n\n            \n            train_accuracy = correct / total * 100\n            fold_metrics[\"train_losses\"].append(running_loss / len(train_loader))\n            fold_metrics[\"train_accuracies\"].append(train_accuracy)\n\n            print(f\"Train Loss: {running_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\") \n\n            # Validation loop with tqdm progress bar\n            model.eval()\n            correct = 0\n            total = 0\n            running_valid_loss = 0.0\n            all_preds = []\n            all_labels = []\n            with tqdm(valid_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\", unit=\"batch\", total=len(valid_loader)) as vepoch:\n                with torch.no_grad():\n                    for inputs, labels in vepoch:\n                        inputs, labels = inputs.to(device), labels.to(device)\n                        labels = labels.float()  # Ensure labels are float for BCEWithLogitsLoss\n                        outputs = model(inputs)\n                        loss = criterion(outputs.squeeze(), labels)\n\n                        running_valid_loss += loss.item()\n\n                        preds = torch.round(torch.sigmoid(outputs))\n                        correct += (preds.squeeze() == labels).sum().item()\n                        total += labels.size(0)\n\n                        all_preds.extend(preds.squeeze().cpu().numpy())\n                        all_labels.extend(labels.cpu().numpy())\n\n                        # Update progress bar\n                        vepoch.set_postfix(loss=running_valid_loss / (vepoch.n + 1), accuracy=correct / total * 100)\n\n                val_accuracy = correct / total * 100\n                fold_metrics[\"valid_losses\"].append(running_valid_loss / len(valid_loader))\n                fold_metrics[\"valid_accuracies\"].append(val_accuracy)\n\n            \n            precision = precision_score(all_labels, all_preds)\n            recall = recall_score(all_labels, all_preds)\n            fold_precision += precision\n            fold_recall += recall\n\n            print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n            print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}\")\n\n            # Save the best model based on validation accuracy\n            if val_accuracy > best_val_accuracy:\n                best_val_accuracy = val_accuracy\n                torch.save(model.state_dict(), f\"best_model_fold_{fold+1}.pth\")\n\n        \n        fold_metrics[\"best_accuracy\"].append(best_val_accuracy)\n        fold_metrics[\"precisions\"].append(fold_precision / num_epochs)\n        fold_metrics[\"recalls\"].append(fold_recall / num_epochs)\n\n    \n    avg_train_loss = sum(fold_metrics[\"train_losses\"]) / len(fold_metrics[\"train_losses\"])\n    avg_valid_loss = sum(fold_metrics[\"valid_losses\"]) / len(fold_metrics[\"valid_losses\"])\n    avg_train_accuracy = sum(fold_metrics[\"train_accuracies\"]) / len(fold_metrics[\"train_accuracies\"])\n    avg_valid_accuracy = sum(fold_metrics[\"valid_accuracies\"]) / len(fold_metrics[\"valid_accuracies\"])\n    avg_precision = sum(fold_metrics[\"precisions\"]) / len(fold_metrics[\"precisions\"])\n    avg_recall = sum(fold_metrics[\"recalls\"]) / len(fold_metrics[\"recalls\"])\n    avg_best_accuracy = sum(fold_metrics[\"best_accuracy\"]) / len(fold_metrics[\"best_accuracy\"])\n\n    print(f\"\\nAverage Train Loss: {avg_train_loss:.4f}, Average Train Accuracy: {avg_train_accuracy:.2f}%\")\n    print(f\"Average Validation Loss: {avg_valid_loss:.4f}, Average Validation Accuracy: {avg_valid_accuracy:.2f}%\")\n    print(f\"Average Precision: {avg_precision:.2f}, Average Recall: {avg_recall:.2f}\")\n    print(f\"Average Best Validation Accuracy: {avg_best_accuracy:.2f}%\")\n\n    return model, fold_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T01:00:59.627844Z","iopub.execute_input":"2024-12-29T01:00:59.628150Z","iopub.status.idle":"2024-12-29T01:00:59.642348Z","shell.execute_reply.started":"2024-12-29T01:00:59.628125Z","shell.execute_reply":"2024-12-29T01:00:59.641298Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def test_model(model, test_loader):\n    model.eval() \n    correct = 0\n    total = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(test_loader, desc=\"Testing\", unit=\"batch\", total=len(test_loader)):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(inputs)  \n            preds = torch.round(torch.sigmoid(outputs))  # Binary predictions (0 or 1)\n\n            # Adjust for correct dimensions\n            all_preds.extend(preds.squeeze(1).cpu().numpy())  \n            all_labels.extend(labels.cpu().numpy()) \n\n            correct += (preds.squeeze(1) == labels).sum().item()\n            total += labels.size(0)\n\n    accuracy = correct / total * 100\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\n    return all_preds, all_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T01:01:06.829816Z","iopub.execute_input":"2024-12-29T01:01:06.830145Z","iopub.status.idle":"2024-12-29T01:01:06.835926Z","shell.execute_reply.started":"2024-12-29T01:01:06.830116Z","shell.execute_reply":"2024-12-29T01:01:06.834923Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"mobile = CustomMobileNet()\n\n# Define the loss function\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(mobile.parameters(), lr=8.948291234170116e-05)\n\ntrain_model(mobile ,combined_dataset, criterion, optimizer, num_epochs=10, k=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T01:08:08.659899Z","iopub.execute_input":"2024-12-29T01:08:08.660204Z","iopub.status.idle":"2024-12-29T02:48:51.806124Z","shell.execute_reply.started":"2024-12-29T01:08:08.660180Z","shell.execute_reply":"2024-12-29T02:48:51.805318Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nFold 1/3\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 240/240 [05:00<00:00,  1.25s/batch, accuracy=83.1, loss=0.43] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4298, Train Accuracy: 83.14%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 1/10: 100%|██████████| 120/120 [02:42<00:00,  1.36s/batch, accuracy=83.4, loss=0.41] \n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 83.36%\nPrecision: 0.62, Recall: 0.02\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 240/240 [02:11<00:00,  1.83batch/s, accuracy=83.6, loss=0.407]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4065, Train Accuracy: 83.56%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 2/10: 100%|██████████| 120/120 [01:01<00:00,  1.96batch/s, accuracy=83.5, loss=0.404]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 83.47%\nPrecision: 0.66, Recall: 0.03\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 240/240 [02:09<00:00,  1.85batch/s, accuracy=83.7, loss=0.394]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3936, Train Accuracy: 83.72%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 3/10: 100%|██████████| 120/120 [01:02<00:00,  1.91batch/s, accuracy=83.8, loss=0.401]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 83.75%\nPrecision: 0.60, Recall: 0.09\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 240/240 [02:04<00:00,  1.92batch/s, accuracy=84.1, loss=0.38] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3801, Train Accuracy: 84.14%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 4/10: 100%|██████████| 120/120 [01:01<00:00,  1.94batch/s, accuracy=83.8, loss=0.398]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 83.78%\nPrecision: 0.58, Recall: 0.12\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 240/240 [02:06<00:00,  1.90batch/s, accuracy=84.6, loss=0.36] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3601, Train Accuracy: 84.63%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 5/10: 100%|██████████| 120/120 [01:03<00:00,  1.90batch/s, accuracy=83.6, loss=0.399]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 83.63%\nPrecision: 0.54, Recall: 0.16\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 240/240 [02:04<00:00,  1.92batch/s, accuracy=85.6, loss=0.339]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3388, Train Accuracy: 85.58%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 6/10: 100%|██████████| 120/120 [01:00<00:00,  1.98batch/s, accuracy=82.9, loss=0.406]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 82.94%\nPrecision: 0.48, Recall: 0.22\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|██████████| 240/240 [02:06<00:00,  1.90batch/s, accuracy=86.7, loss=0.314]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3135, Train Accuracy: 86.73%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 7/10: 100%|██████████| 120/120 [01:01<00:00,  1.96batch/s, accuracy=83.7, loss=0.42] \n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 83.73%\nPrecision: 0.55, Recall: 0.16\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 240/240 [02:06<00:00,  1.90batch/s, accuracy=88.1, loss=0.282]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2818, Train Accuracy: 88.08%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 8/10: 100%|██████████| 120/120 [01:01<00:00,  1.94batch/s, accuracy=83.1, loss=0.433]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 83.14%\nPrecision: 0.49, Recall: 0.21\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 240/240 [02:04<00:00,  1.93batch/s, accuracy=89.3, loss=0.255]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2553, Train Accuracy: 89.30%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 9/10: 100%|██████████| 120/120 [01:11<00:00,  1.68batch/s, accuracy=83.1, loss=0.446]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 83.14%\nPrecision: 0.49, Recall: 0.23\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 240/240 [02:16<00:00,  1.76batch/s, accuracy=90.9, loss=0.219]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2193, Train Accuracy: 90.88%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 10/10: 100%|██████████| 120/120 [01:03<00:00,  1.89batch/s, accuracy=82.4, loss=0.463]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 82.37%\nPrecision: 0.46, Recall: 0.30\n\nFold 2/3\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 240/240 [02:04<00:00,  1.93batch/s, accuracy=86.8, loss=0.334]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3343, Train Accuracy: 86.83%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 1/10: 100%|██████████| 120/120 [01:01<00:00,  1.96batch/s, accuracy=92.4, loss=0.194]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 92.40%\nPrecision: 0.98, Recall: 0.56\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 240/240 [02:22<00:00,  1.69batch/s, accuracy=87.9, loss=0.303]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3027, Train Accuracy: 87.91%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 2/10: 100%|██████████| 120/120 [01:01<00:00,  1.96batch/s, accuracy=92.8, loss=0.188]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 92.83%\nPrecision: 0.95, Recall: 0.60\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 240/240 [02:04<00:00,  1.93batch/s, accuracy=89.1, loss=0.273]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2733, Train Accuracy: 89.12%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 3/10: 100%|██████████| 120/120 [01:01<00:00,  1.94batch/s, accuracy=94.6, loss=0.167]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 94.57%\nPrecision: 0.92, Recall: 0.74\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 240/240 [02:07<00:00,  1.89batch/s, accuracy=90.2, loss=0.248]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2478, Train Accuracy: 90.21%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 4/10: 100%|██████████| 120/120 [01:03<00:00,  1.88batch/s, accuracy=93.6, loss=0.174]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 93.58%\nPrecision: 0.90, Recall: 0.69\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 240/240 [02:07<00:00,  1.88batch/s, accuracy=91.4, loss=0.219]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2187, Train Accuracy: 91.42%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 5/10: 100%|██████████| 120/120 [01:01<00:00,  1.95batch/s, accuracy=91.4, loss=0.192]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 91.38%\nPrecision: 0.96, Recall: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 240/240 [02:04<00:00,  1.92batch/s, accuracy=92.4, loss=0.194]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1936, Train Accuracy: 92.40%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 6/10: 100%|██████████| 120/120 [01:03<00:00,  1.90batch/s, accuracy=93.1, loss=0.167]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 93.06%\nPrecision: 0.92, Recall: 0.64\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|██████████| 240/240 [02:09<00:00,  1.85batch/s, accuracy=93.4, loss=0.17] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1697, Train Accuracy: 93.35%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 7/10: 100%|██████████| 120/120 [01:01<00:00,  1.94batch/s, accuracy=92.7, loss=0.176]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 92.66%\nPrecision: 0.91, Recall: 0.62\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 240/240 [02:04<00:00,  1.93batch/s, accuracy=93.9, loss=0.154]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1538, Train Accuracy: 93.94%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 8/10: 100%|██████████| 120/120 [01:01<00:00,  1.94batch/s, accuracy=92.1, loss=0.191]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 92.13%\nPrecision: 0.92, Recall: 0.58\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 240/240 [02:08<00:00,  1.87batch/s, accuracy=94.5, loss=0.139]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1393, Train Accuracy: 94.51%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 9/10: 100%|██████████| 120/120 [01:01<00:00,  1.96batch/s, accuracy=92.1, loss=0.196]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 92.10%\nPrecision: 0.89, Recall: 0.60\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 240/240 [02:06<00:00,  1.90batch/s, accuracy=95.2, loss=0.123]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1233, Train Accuracy: 95.21%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 10/10: 100%|██████████| 120/120 [01:04<00:00,  1.85batch/s, accuracy=92, loss=0.198]  \n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 92.04%\nPrecision: 0.88, Recall: 0.61\n\nFold 3/3\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 240/240 [02:12<00:00,  1.81batch/s, accuracy=91.1, loss=0.224]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2239, Train Accuracy: 91.09%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 1/10: 100%|██████████| 120/120 [01:06<00:00,  1.81batch/s, accuracy=99.4, loss=0.0467]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.40%\nPrecision: 1.00, Recall: 0.97\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 240/240 [02:17<00:00,  1.74batch/s, accuracy=92.7, loss=0.182]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1818, Train Accuracy: 92.67%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 2/10: 100%|██████████| 120/120 [01:02<00:00,  1.93batch/s, accuracy=99.2, loss=0.0403]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.20%\nPrecision: 1.00, Recall: 0.96\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 240/240 [02:07<00:00,  1.89batch/s, accuracy=93.6, loss=0.162]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1619, Train Accuracy: 93.58%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 3/10: 100%|██████████| 120/120 [01:02<00:00,  1.93batch/s, accuracy=99, loss=0.0395]  \n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.02%\nPrecision: 0.99, Recall: 0.95\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 240/240 [02:13<00:00,  1.80batch/s, accuracy=94.3, loss=0.144]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1436, Train Accuracy: 94.29%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 4/10: 100%|██████████| 120/120 [01:02<00:00,  1.91batch/s, accuracy=99.1, loss=0.0376]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.13%\nPrecision: 1.00, Recall: 0.95\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 240/240 [02:05<00:00,  1.91batch/s, accuracy=95.1, loss=0.129]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1288, Train Accuracy: 95.10%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 5/10: 100%|██████████| 120/120 [01:05<00:00,  1.84batch/s, accuracy=98.9, loss=0.0412]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 98.92%\nPrecision: 0.99, Recall: 0.94\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 240/240 [02:18<00:00,  1.73batch/s, accuracy=95.2, loss=0.121]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1211, Train Accuracy: 95.23%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 6/10: 100%|██████████| 120/120 [01:13<00:00,  1.64batch/s, accuracy=98.7, loss=0.0409]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 98.75%\nPrecision: 0.99, Recall: 0.93\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|██████████| 240/240 [02:09<00:00,  1.85batch/s, accuracy=95.9, loss=0.105] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1046, Train Accuracy: 95.91%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 7/10: 100%|██████████| 120/120 [01:02<00:00,  1.93batch/s, accuracy=98.7, loss=0.0461]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 98.65%\nPrecision: 0.96, Recall: 0.96\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 240/240 [02:09<00:00,  1.86batch/s, accuracy=96.1, loss=0.103] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1033, Train Accuracy: 96.07%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 8/10: 100%|██████████| 120/120 [01:06<00:00,  1.80batch/s, accuracy=98.2, loss=0.0542]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 98.16%\nPrecision: 0.96, Recall: 0.92\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 240/240 [02:06<00:00,  1.90batch/s, accuracy=96.4, loss=0.0939]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0939, Train Accuracy: 96.44%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 9/10: 100%|██████████| 120/120 [01:00<00:00,  2.00batch/s, accuracy=98.3, loss=0.0475]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 98.32%\nPrecision: 0.98, Recall: 0.92\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 240/240 [02:05<00:00,  1.91batch/s, accuracy=96.6, loss=0.0894]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0894, Train Accuracy: 96.56%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 10/10: 100%|██████████| 120/120 [01:11<00:00,  1.69batch/s, accuracy=97.7, loss=0.0624]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 97.67%\nPrecision: 0.98, Recall: 0.88\n\nAverage Train Loss: 0.2296, Average Train Accuracy: 90.72%\nAverage Validation Loss: 0.2159, Average Validation Accuracy: 91.58%\nAverage Precision: 0.82, Average Recall: 0.57\nAverage Best Validation Accuracy: 92.58%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(CustomMobileNet(\n   (features): Sequential(\n     (0): Conv2dNormActivation(\n       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (2): ReLU6(inplace=True)\n     )\n     (1): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n           (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (2): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (3): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (4): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (5): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (6): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (7): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (8): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (9): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (10): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (11): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (12): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (13): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (14): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (15): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (16): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (17): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (18): Conv2dNormActivation(\n       (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n       (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (2): ReLU6(inplace=True)\n     )\n   )\n   (classifier): Sequential(\n     (0): Linear(in_features=1280, out_features=4096, bias=True)\n     (1): ReLU(inplace=True)\n     (2): Dropout(p=0.5, inplace=False)\n     (3): Linear(in_features=4096, out_features=4096, bias=True)\n     (4): ReLU(inplace=True)\n     (5): Dropout(p=0.5, inplace=False)\n     (6): Linear(in_features=4096, out_features=1, bias=True)\n   )\n ),\n {'train_losses': [0.42978167918821175,\n   0.406515272334218,\n   0.39359903149306774,\n   0.38009126919011277,\n   0.3600990145156781,\n   0.3387709838648637,\n   0.3135192439580957,\n   0.28181801245858273,\n   0.2552991922944784,\n   0.2193499702339371,\n   0.33427400154372056,\n   0.30265167945375043,\n   0.2733456405500571,\n   0.24775677813837926,\n   0.21868898229052622,\n   0.19360939478501676,\n   0.16967651173472403,\n   0.15384459060927233,\n   0.13929046324143807,\n   0.12327141033795973,\n   0.2239151868658761,\n   0.18181613919635614,\n   0.16185719575732946,\n   0.14356453786604106,\n   0.12876300985614458,\n   0.12113796188496054,\n   0.1045951430996259,\n   0.10331742581911385,\n   0.09386738503041367,\n   0.08941168524324894],\n  'valid_losses': [0.4097518810381492,\n   0.4043330104400714,\n   0.4014493638028701,\n   0.3975308009733756,\n   0.39858227322498957,\n   0.4064083146552245,\n   0.4195402003824711,\n   0.4333027504384518,\n   0.445773346349597,\n   0.46254779485364755,\n   0.19400205090641975,\n   0.1877753213668863,\n   0.1666784747193257,\n   0.17367756503323714,\n   0.19170860297357042,\n   0.16723758795609076,\n   0.17639004449980955,\n   0.19069821316127974,\n   0.19564735546397666,\n   0.19777902201749384,\n   0.04674524793711801,\n   0.04026584420353174,\n   0.039483694514880575,\n   0.03761889539503803,\n   0.04118237320023278,\n   0.04087205281636367,\n   0.046138328049952784,\n   0.05417051096446812,\n   0.04754851280789201,\n   0.06242690094513818],\n  'train_accuracies': [83.13958333333333,\n   83.55625,\n   83.72291666666666,\n   84.14166666666667,\n   84.63333333333334,\n   85.575,\n   86.72708333333333,\n   88.08333333333334,\n   89.30416666666666,\n   90.87916666666666,\n   86.83333333333333,\n   87.91458333333333,\n   89.125,\n   90.21458333333334,\n   91.425,\n   92.40208333333332,\n   93.35416666666667,\n   93.93958333333333,\n   94.50625000000001,\n   95.21041666666666,\n   91.08541666666666,\n   92.675,\n   93.57916666666667,\n   94.29166666666666,\n   95.10416666666667,\n   95.22500000000001,\n   95.91041666666666,\n   96.06666666666666,\n   96.43541666666667,\n   96.5625],\n  'valid_accuracies': [83.3625,\n   83.46666666666667,\n   83.75416666666666,\n   83.775,\n   83.62916666666666,\n   82.94166666666666,\n   83.72500000000001,\n   83.1375,\n   83.14166666666667,\n   82.37083333333334,\n   92.40416666666667,\n   92.82916666666667,\n   94.57083333333334,\n   93.57916666666667,\n   91.375,\n   93.0625,\n   92.66250000000001,\n   92.12916666666666,\n   92.10416666666667,\n   92.04166666666667,\n   99.4,\n   99.2,\n   99.01666666666667,\n   99.12916666666666,\n   98.91666666666666,\n   98.74583333333334,\n   98.65,\n   98.1625,\n   98.32499999999999,\n   97.67083333333333],\n  'precisions': [0.5467606068451005, 0.921531196465239, 0.985315157527069],\n  'recalls': [0.1516546404578253, 0.6146963259185203, 0.936934673366834],\n  'best_accuracy': [83.775, 94.57083333333334, 99.4]})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"mobile.unfreeze_last_layers(2)\n\n\n# Define the loss function\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(mobile.parameters(), lr=8.948291234170116e-05)\n\ntrain_model(mobile ,combined_dataset, criterion, optimizer, num_epochs=5, k=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T02:51:44.127466Z","iopub.execute_input":"2024-12-29T02:51:44.127821Z","iopub.status.idle":"2024-12-29T03:41:10.230125Z","shell.execute_reply.started":"2024-12-29T02:51:44.127790Z","shell.execute_reply":"2024-12-29T03:41:10.229299Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nFold 1/3\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 240/240 [02:10<00:00,  1.84batch/s, accuracy=94.5, loss=0.143]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1432, Train Accuracy: 94.50%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 1/5: 100%|██████████| 120/120 [01:02<00:00,  1.93batch/s, accuracy=99.5, loss=0.0261]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.52%\nPrecision: 1.00, Recall: 0.97\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 240/240 [02:07<00:00,  1.88batch/s, accuracy=95.5, loss=0.116]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1159, Train Accuracy: 95.47%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 2/5: 100%|██████████| 120/120 [01:01<00:00,  1.94batch/s, accuracy=99.1, loss=0.0359]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.06%\nPrecision: 0.98, Recall: 0.96\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 240/240 [02:08<00:00,  1.87batch/s, accuracy=95.9, loss=0.105] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1052, Train Accuracy: 95.94%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 3/5: 100%|██████████| 120/120 [01:01<00:00,  1.94batch/s, accuracy=98.4, loss=0.0451]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 98.44%\nPrecision: 0.99, Recall: 0.91\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 240/240 [02:07<00:00,  1.88batch/s, accuracy=96.5, loss=0.0931]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0931, Train Accuracy: 96.51%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 4/5: 100%|██████████| 120/120 [01:01<00:00,  1.95batch/s, accuracy=98.1, loss=0.053] \n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 98.11%\nPrecision: 0.99, Recall: 0.90\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 240/240 [02:07<00:00,  1.88batch/s, accuracy=96.9, loss=0.0821]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0821, Train Accuracy: 96.89%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 5/5: 100%|██████████| 120/120 [01:09<00:00,  1.74batch/s, accuracy=96.3, loss=0.0901]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 96.28%\nPrecision: 0.99, Recall: 0.79\n\nFold 2/3\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 240/240 [02:09<00:00,  1.86batch/s, accuracy=95.6, loss=0.118]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1181, Train Accuracy: 95.57%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 1/5: 100%|██████████| 120/120 [01:03<00:00,  1.88batch/s, accuracy=99.5, loss=0.0245]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.48%\nPrecision: 0.99, Recall: 0.98\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 240/240 [02:19<00:00,  1.72batch/s, accuracy=96.3, loss=0.0972]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0972, Train Accuracy: 96.34%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 2/5: 100%|██████████| 120/120 [01:09<00:00,  1.73batch/s, accuracy=99, loss=0.0316]  \n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 98.97%\nPrecision: 1.00, Recall: 0.94\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 240/240 [02:10<00:00,  1.84batch/s, accuracy=96.9, loss=0.0818]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0818, Train Accuracy: 96.95%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 3/5: 100%|██████████| 120/120 [01:06<00:00,  1.81batch/s, accuracy=99.2, loss=0.0283]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.25%\nPrecision: 0.99, Recall: 0.97\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 240/240 [02:07<00:00,  1.89batch/s, accuracy=97.2, loss=0.0747]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0747, Train Accuracy: 97.22%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 4/5: 100%|██████████| 120/120 [01:26<00:00,  1.39batch/s, accuracy=99.2, loss=0.0289]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.23%\nPrecision: 0.99, Recall: 0.97\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 240/240 [02:09<00:00,  1.85batch/s, accuracy=97.3, loss=0.0729]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0729, Train Accuracy: 97.25%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 5/5: 100%|██████████| 120/120 [01:02<00:00,  1.93batch/s, accuracy=98.4, loss=0.0443]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 98.40%\nPrecision: 0.98, Recall: 0.92\n\nFold 3/3\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 240/240 [02:09<00:00,  1.85batch/s, accuracy=96.1, loss=0.105]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1045, Train Accuracy: 96.06%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 1/5: 100%|██████████| 120/120 [01:02<00:00,  1.91batch/s, accuracy=99.7, loss=0.0154]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.66%\nPrecision: 1.00, Recall: 0.98\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 240/240 [02:07<00:00,  1.89batch/s, accuracy=97, loss=0.0818]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0818, Train Accuracy: 96.95%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 2/5: 100%|██████████| 120/120 [01:07<00:00,  1.78batch/s, accuracy=99.3, loss=0.0219]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.30%\nPrecision: 0.99, Recall: 0.97\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 240/240 [02:31<00:00,  1.59batch/s, accuracy=97.2, loss=0.0733]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0733, Train Accuracy: 97.18%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 3/5: 100%|██████████| 120/120 [01:12<00:00,  1.65batch/s, accuracy=99.2, loss=0.0229]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.22%\nPrecision: 0.99, Recall: 0.96\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 240/240 [02:19<00:00,  1.72batch/s, accuracy=97.5, loss=0.0656]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0656, Train Accuracy: 97.54%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 4/5: 100%|██████████| 120/120 [01:03<00:00,  1.90batch/s, accuracy=99.2, loss=0.0252]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.20%\nPrecision: 0.99, Recall: 0.97\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 240/240 [02:06<00:00,  1.90batch/s, accuracy=97.6, loss=0.0629]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0629, Train Accuracy: 97.63%\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 5/5: 100%|██████████| 120/120 [01:01<00:00,  1.95batch/s, accuracy=99.2, loss=0.0246]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 99.20%\nPrecision: 1.00, Recall: 0.96\n\nAverage Train Loss: 0.0915, Average Train Accuracy: 96.53%\nAverage Validation Loss: 0.0345, Average Validation Accuracy: 98.89%\nAverage Precision: 0.99, Average Recall: 0.94\nAverage Best Validation Accuracy: 99.56%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(CustomMobileNet(\n   (features): Sequential(\n     (0): Conv2dNormActivation(\n       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (2): ReLU6(inplace=True)\n     )\n     (1): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n           (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (2): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (3): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (4): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (5): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (6): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (7): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (8): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (9): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (10): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (11): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (12): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (13): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (14): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (15): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (16): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (17): InvertedResidual(\n       (conv): Sequential(\n         (0): Conv2dNormActivation(\n           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (1): Conv2dNormActivation(\n           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n           (2): ReLU6(inplace=True)\n         )\n         (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (18): Conv2dNormActivation(\n       (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n       (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (2): ReLU6(inplace=True)\n     )\n   )\n   (classifier): Sequential(\n     (0): Linear(in_features=1280, out_features=4096, bias=True)\n     (1): ReLU(inplace=True)\n     (2): Dropout(p=0.5, inplace=False)\n     (3): Linear(in_features=4096, out_features=4096, bias=True)\n     (4): ReLU(inplace=True)\n     (5): Dropout(p=0.5, inplace=False)\n     (6): Linear(in_features=4096, out_features=1, bias=True)\n   )\n ),\n {'train_losses': [0.1431831722923865,\n   0.11593976450773577,\n   0.10523106171749533,\n   0.0931278997954602,\n   0.08213875731453299,\n   0.1180993458100905,\n   0.09721514543052763,\n   0.08177982224151492,\n   0.07474079448729753,\n   0.07287815313320607,\n   0.10453872683768471,\n   0.0818020451037834,\n   0.07330070123231659,\n   0.06564222151258339,\n   0.06294198150280864],\n  'valid_losses': [0.026104700495488943,\n   0.03589038676582277,\n   0.04509824274961526,\n   0.05303773900959641,\n   0.09009447772599136,\n   0.024547618386956554,\n   0.031579789067230496,\n   0.028252427473974724,\n   0.028865987345731505,\n   0.044333511253353206,\n   0.015366058957685407,\n   0.02188862523956535,\n   0.022935352588926133,\n   0.025234308142292623,\n   0.024618378174879278],\n  'train_accuracies': [94.49791666666667,\n   95.46875,\n   95.93541666666667,\n   96.50833333333333,\n   96.8875,\n   95.56875000000001,\n   96.34166666666667,\n   96.94791666666667,\n   97.21666666666667,\n   97.25416666666666,\n   96.05833333333334,\n   96.95,\n   97.17708333333334,\n   97.54166666666667,\n   97.62916666666666],\n  'valid_accuracies': [99.52499999999999,\n   99.0625,\n   98.4375,\n   98.1125,\n   96.28333333333333,\n   99.47916666666666,\n   98.96666666666667,\n   99.24583333333334,\n   99.22916666666667,\n   98.40416666666667,\n   99.6625,\n   99.29583333333333,\n   99.21666666666667,\n   99.2,\n   99.19583333333334],\n  'precisions': [0.9892844908313112, 0.9884065937190132, 0.9922694599439446],\n  'recalls': [0.9072406071161982, 0.9551112221944514, 0.9661809045226131],\n  'best_accuracy': [99.52499999999999, 99.47916666666666, 99.6625]})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"test_model(mobile,test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T03:42:58.501545Z","iopub.execute_input":"2024-12-29T03:42:58.501865Z","iopub.status.idle":"2024-12-29T03:44:42.395591Z","shell.execute_reply.started":"2024-12-29T03:42:58.501833Z","shell.execute_reply":"2024-12-29T03:44:42.394803Z"}},"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 12000/12000 [01:43<00:00, 115.54batch/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 84.10%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"([0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  0.0,\n  ...],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  ...])"},"metadata":{}}],"execution_count":18}]}